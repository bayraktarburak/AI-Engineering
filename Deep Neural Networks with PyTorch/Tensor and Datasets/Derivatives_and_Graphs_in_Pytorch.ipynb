{"cells":[{"cell_type":"markdown","id":"1a520396-ba54-4024-ae52-c27907a73c2d","metadata":{},"source":["<h1>Differentiation in PyTorch</h1> \n"]},{"cell_type":"markdown","id":"ec3b506e-005f-46f1-a3e6-89e602942ebb","metadata":{},"source":["<h2>Objective</h2><ul><li> How to perform differentiation in pytorch.</li></ul> \n"]},{"cell_type":"markdown","id":"3c711721-7179-49d7-a225-b601bb2d5c04","metadata":{},"source":["<h2>Table of Contents</h2>\n","\n","<p>In this lab, you will learn the basics of differentiation.</p> \n","\n","<ul>\n","    <li><a href=\"#Derivative\">Derivatives</a></li>\n","    <li><a href=\"#Partial_Derivative\">Partial Derivatives</a></li>\n","</ul>\n","<hr>\n"]},{"cell_type":"markdown","id":"0f0991d8-0361-40a3-baeb-5f81f5aceabe","metadata":{},"source":["<h2>Preparation</h2>\n"]},{"cell_type":"markdown","id":"aaa14b17-713c-4706-b38a-e76b0f553593","metadata":{},"source":["The following are the libraries we are going to use for this lab.\n"]},{"cell_type":"code","execution_count":null,"id":"384b3fdb-04f1-4f3b-8984-7159c8169a9d","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# These are the libraries will be useing for this lab.\n","\n","import torch \n","import matplotlib.pylab as plt\n"]},{"cell_type":"markdown","id":"8cab73a1-4717-4a0f-9bff-0e08cf22d2e9","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"af64b863-5c38-4de3-baf8-06626163012e","metadata":{},"source":["<h2 id=\"Derivative\">Derivatives</h2>\n"]},{"cell_type":"markdown","id":"03734c5e-64ab-4888-81e8-712ee2de71ee","metadata":{},"source":["Let us create the tensor <code>x</code> and set the parameter <code>requires_grad</code> to true because you are going to take the derivative of the tensor.\n"]},{"cell_type":"code","execution_count":null,"id":"23ea3091-9c56-4f29-aae3-572798823318","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Create a tensor x\n","\n","x = torch.tensor(2.0, requires_grad = True)\n","print(\"The tensor x: \", x)"]},{"cell_type":"markdown","id":"1678f759-5e39-4995-b9e4-d2f72b132ab7","metadata":{},"source":["Then let us create a tensor according to the equation $ y=x^2 $.\n"]},{"cell_type":"code","execution_count":null,"id":"6e0c9302-ce8e-4581-8e66-7f3e04e10711","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Create a tensor y according to y = x^2\n","\n","y = x ** 2\n","print(\"The result of y = x^2: \", y)"]},{"cell_type":"markdown","id":"31b6713d-83bc-49ae-8162-b8ebd3e5f5d7","metadata":{},"source":["Then let us take the derivative with respect x at x = 2\n"]},{"cell_type":"code","execution_count":null,"id":"7771c23c-6c37-4af4-8708-524e1e835441","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Take the derivative. Try to print out the derivative at the value x = 2\n","\n","y.backward()\n","print(\"The dervative at x = 2: \", x.grad)"]},{"cell_type":"markdown","id":"eac58936-2239-44d6-8cce-4fa358c9ca51","metadata":{},"source":["The preceding lines perform the following operation: \n"]},{"cell_type":"markdown","id":"a38194d4-3d6d-467e-90f5-d09770dc8ce3","metadata":{},"source":["$\\frac{\\mathrm{dy(x)}}{\\mathrm{dx}}=2x$\n"]},{"cell_type":"markdown","id":"402f6899-46cd-43cf-8b65-baeb3b17073a","metadata":{},"source":["$\\frac{\\mathrm{dy(x=2)}}{\\mathrm{dx}}=2(2)=4$\n"]},{"cell_type":"code","execution_count":null,"id":"766effb7-f216-4311-a3b6-d2c921e30e5c","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"8ecbd01e-392c-470f-adb0-b527810e7083","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["print('data:',x.data)\n","print('grad_fn:',x.grad_fn)\n","print('grad:',x.grad)\n","print(\"is_leaf:\",x.is_leaf)\n","print(\"requires_grad:\",x.requires_grad)"]},{"cell_type":"code","execution_count":null,"id":"89b66f32-b87c-4409-8994-e9063bc740be","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["print('data:',y.data)\n","print('grad_fn:',y.grad_fn)\n","print('grad:',y.grad)\n","print(\"is_leaf:\",y.is_leaf)\n","print(\"requires_grad:\",y.requires_grad)"]},{"cell_type":"markdown","id":"27d85316-888a-4e8e-a0d7-98df18754ef6","metadata":{},"source":["Let us try to calculate the derivative for a more complicated function. \n"]},{"cell_type":"code","execution_count":null,"id":"11f8300d-9fb7-46ff-a221-03de436e2cf8","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Calculate the y = x^2 + 2x + 1, then find the derivative \n","\n","x = torch.tensor(2.0, requires_grad = True)\n","y = x ** 2 + 2 * x + 1\n","print(\"The result of y = x^2 + 2x + 1: \", y)\n","y.backward()\n","print(\"The dervative at x = 2: \", x.grad)"]},{"cell_type":"markdown","id":"a5b5cd0b-621b-47f0-83b5-aa2597a1c603","metadata":{},"source":["The function is in the following form:\n","$y=x^{2}+2x+1$\n"]},{"cell_type":"markdown","id":"edf63377-ce30-4230-8fc6-2f8eb4038213","metadata":{},"source":["The derivative is given by:\n"]},{"cell_type":"markdown","id":"d2e8a54d-836a-4080-9f22-235109accf7c","metadata":{},"source":["$\\frac{\\mathrm{dy(x)}}{\\mathrm{dx}}=2x+2$\n","\n","$\\frac{\\mathrm{dy(x=2)}}{\\mathrm{dx}}=2(2)+2=6$\n"]},{"cell_type":"markdown","id":"743c8dce-a8d1-4f21-af01-86063847852c","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"98d63785-a340-4bf8-b973-07d001ad1ea4","metadata":{},"source":["<h3>Practice</h3>\n"]},{"cell_type":"markdown","id":"0d109dd0-680c-415a-a5d0-7f1b1d1e02d8","metadata":{},"source":["Determine the derivative of $ y = 2x^3+x $ at $x=1$\n"]},{"cell_type":"code","execution_count":null,"id":"e6042c63-71d5-4c59-b4b0-9943ec3e8a64","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Practice: Calculate the derivative of y = 2x^3 + x at x = 1\n","\n","# Type your code here"]},{"cell_type":"markdown","id":"56c52df7-9de3-420a-a38b-3edcda837424","metadata":{},"source":["Double-click <b>here</b> for the solution.\n","<!-- \n","x = torch.tensor(1.0, requires_grad=True)\n","y = 2 * x ** 3 + x\n","y.backward()\n","print(\"The derivative result: \", x.grad)\n"," -->\n"]},{"cell_type":"markdown","id":"66a22818-200d-4e6c-971d-740a4d3dcd8c","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"1cb7bc06-f030-4bfe-8daa-a47a9ac80d18","metadata":{},"source":[" We can implement our own custom autograd Functions by subclassing\n","    torch.autograd.Function and implementing the forward and backward passes\n","    which operate on Tensors\n"]},{"cell_type":"code","execution_count":null,"id":"3ce0dade-a0d7-4e64-a849-6487c1942a57","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["class SQ(torch.autograd.Function):\n","\n","\n","    @staticmethod\n","    def forward(ctx,i):\n","        \"\"\"\n","        In the forward pass we receive a Tensor containing the input and return\n","        a Tensor containing the output. ctx is a context object that can be used\n","        to stash information for backward computation. You can cache arbitrary\n","        objects for use in the backward pass using the ctx.save_for_backward method.\n","        \"\"\"\n","        result=i**2\n","        ctx.save_for_backward(i)\n","        return result\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        \"\"\"\n","        In the backward pass we receive a Tensor containing the gradient of the loss\n","        with respect to the output, and we need to compute the gradient of the loss\n","        with respect to the input.\n","        \"\"\"\n","        i, = ctx.saved_tensors\n","        grad_output = 2*i\n","        return grad_output"]},{"cell_type":"markdown","id":"a896eaa3-00ae-4690-aa0c-81abdcecdac4","metadata":{},"source":["We can apply it the function  \n"]},{"cell_type":"code","execution_count":null,"id":"0eb13a96-5a67-47ed-b815-fb7713960a50","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["x=torch.tensor(2.0,requires_grad=True )\n","sq=SQ.apply\n","\n","y=sq(x)\n","y\n","print(y.grad_fn)\n","y.backward()\n","x.grad"]},{"cell_type":"markdown","id":"ddab5900-cfd9-4ccb-b529-9175142d6edc","metadata":{},"source":["<h2 id=\"Partial_Derivative\">Partial Derivatives</h2>\n"]},{"cell_type":"markdown","id":"511a912c-2406-4981-8073-f452b3e038de","metadata":{},"source":["We can also calculate <b>Partial Derivatives</b>. Consider the function: $f(u,v)=vu+u^{2}$\n"]},{"cell_type":"markdown","id":"1fc4036e-e7f2-4caa-980a-9ca4a5162c18","metadata":{},"source":["Let us create <code>u</code> tensor, <code>v</code> tensor and  <code>f</code> tensor\n"]},{"cell_type":"code","execution_count":null,"id":"4fa5df39-fc37-4b42-aa5b-1f7b5b7b097e","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Calculate f(u, v) = v * u + u^2 at u = 1, v = 2\n","\n","u = torch.tensor(1.0,requires_grad=True)\n","v = torch.tensor(2.0,requires_grad=True)\n","f = u * v + u ** 2\n","print(\"The result of v * u + u^2: \", f)"]},{"cell_type":"markdown","id":"b04b7c7d-49f4-4c7b-85ca-a2a44b17bd65","metadata":{},"source":["This is equivalent to the following: \n"]},{"cell_type":"markdown","id":"64fbb601-57d7-416f-a4c1-ad54a92687aa","metadata":{},"source":["$f(u=1,v=2)=(2)(1)+1^{2}=3$\n"]},{"cell_type":"markdown","id":"e38c0a55-ab7a-48a2-a9e7-091a035dec42","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"7d15041b-9eeb-4691-a3f5-56a43c307eb5","metadata":{},"source":["Now let us take the derivative with respect to <code>u</code>:\n"]},{"cell_type":"code","execution_count":null,"id":"3ae9cd7c-7524-4c87-bf4c-55dacc34b82e","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Calculate the derivative with respect to u\n","\n","f.backward()\n","print(\"The partial derivative with respect to u: \", u.grad)"]},{"cell_type":"markdown","id":"673b8725-ebfa-42fc-8c59-7556d6592515","metadata":{},"source":["the expression is given by:\n"]},{"cell_type":"markdown","id":"90b99dce-ad6f-45d7-a025-39a87071118c","metadata":{},"source":["$\\frac{\\mathrm{\\partial f(u,v)}}{\\partial {u}}=v+2u$\n","\n","$\\frac{\\mathrm{\\partial f(u=1,v=2)}}{\\partial {u}}=2+2(1)=4$\n"]},{"cell_type":"markdown","id":"ee5e2b32-dc79-4d50-b262-5f170178873f","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"cf5dda66-2c4c-4ea6-953c-576aa9f5f38b","metadata":{},"source":["Now, take the derivative with respect to <code>v</code>:\n"]},{"cell_type":"code","execution_count":null,"id":"99b46de9-9c4b-4f0e-b1a6-0a802cec0c6d","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Calculate the derivative with respect to v\n","\n","print(\"The partial derivative with respect to u: \", v.grad)"]},{"cell_type":"markdown","id":"6dec4dc1-a18b-41c7-982d-e8d634d07967","metadata":{},"source":["The equation is given by:\n"]},{"cell_type":"markdown","id":"1f2855b5-93f2-45f0-b183-2eae2e10bf46","metadata":{},"source":["$\\frac{\\mathrm{\\partial f(u,v)}}{\\partial {v}}=u$\n","\n","$\\frac{\\mathrm{\\partial f(u=1,v=2)}}{\\partial {v}}=1$\n"]},{"cell_type":"markdown","id":"e5899a97-18fc-4cdf-a389-406217a1c397","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"ed09a3e5-ba1b-474e-8bb2-aa0e60d2ea6e","metadata":{},"source":["Calculate the derivative with respect to a function with multiple values as follows. You use the sum trick to produce a scalar valued function and then take the gradient: \n"]},{"cell_type":"code","execution_count":null,"id":"9abb4aac-68f1-4f7c-be4a-af8e4cdf3580","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Calculate the derivative with multiple values\n","\n","x = torch.linspace(-10, 10, 10, requires_grad = True)\n","Y = x ** 2\n","y = torch.sum(x ** 2)"]},{"cell_type":"markdown","id":"eaa65b72-2d34-44dd-9ebc-035cf4495274","metadata":{},"source":["We can plot the function  and its derivative \n"]},{"cell_type":"code","execution_count":null,"id":"4aa90f2b-d22d-4f3b-a57a-11f16b767aea","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Take the derivative with respect to multiple value. Plot out the function and its derivative\n","\n","y.backward()\n","\n","plt.plot(x.detach().numpy(), Y.detach().numpy(), label = 'function')\n","plt.plot(x.detach().numpy(), x.grad.detach().numpy(), label = 'derivative')\n","plt.xlabel('x')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","id":"dfd4a676-ee80-4df1-8f23-5d408d7719fb","metadata":{},"source":["The orange line is the slope of the blue line at the intersection point, which is the derivative of the blue line.\n"]},{"cell_type":"markdown","id":"f4053904-6a20-4597-a449-224f6cf80a1b","metadata":{},"source":["The  method <code> detach()</code>  excludes further tracking of operations in the graph, and therefore the subgraph will not record operations. This allows us to then convert the tensor to a numpy array. To understand the sum operation  <a href=\"https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\">Click Here</a>\n","\n"]},{"cell_type":"markdown","id":"58baf4fd-96e7-448f-9e2c-3ee89b8a8cae","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"944b7e43-4530-493e-bf83-b83459f031b4","metadata":{},"source":["The <b>relu</b> activation function is an essential function in neural networks. We can take the derivative as follows: \n"]},{"cell_type":"code","execution_count":null,"id":"bba2e198-a903-4b26-b069-d8f61254d23b","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b5ecbd6c-694e-4605-960c-b59032631d99","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Take the derivative of Relu with respect to multiple value. Plot out the function and its derivative\n","\n","x = torch.linspace(-10, 10, 1000, requires_grad = True)\n","Y = torch.relu(x)\n","y = Y.sum()\n","y.backward()\n","plt.plot(x.detach().numpy(), Y.detach().numpy(), label = 'function')\n","plt.plot(x.detach().numpy(), x.grad.detach().numpy(), label = 'derivative')\n","plt.xlabel('x')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","id":"ce98a55f-4438-48c8-9793-416c54dd5591","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"code","execution_count":null,"id":"b0574473-e08f-4edc-9161-544d8f1c361b","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["y.grad_fn"]},{"cell_type":"markdown","id":"9c39d31c-9034-442b-a51a-592556a577df","metadata":{},"source":["<h3>Practice</h3>\n"]},{"cell_type":"markdown","id":"daa16bc2-e484-42e0-80cd-46bcf0aa9970","metadata":{},"source":["Try to determine partial derivative  $u$ of the following function where $u=2$ and $v=1$: $ f=uv+(uv)^2$\n"]},{"cell_type":"code","execution_count":null,"id":"1f97bc79-00c7-4d74-bd43-4614ef89c7fa","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Practice: Calculate the derivative of f = u * v + (u * v) ** 2 at u = 2, v = 1\n","\n","# Type the code here"]},{"cell_type":"markdown","id":"4c37ca1b-dc03-4825-9add-6686b8ccf36a","metadata":{},"source":["Double-click __here__ for the solution.\n","<!-- \n","u = torch.tensor(2.0, requires_grad = True)\n","v = torch.tensor(1.0, requires_grad = True)\n","f = u * v + (u * v) ** 2\n","f.backward()\n","print(\"The result is \", u.grad)\n"," -->\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}
