{"cells":[{"cell_type":"markdown","id":"5d31ac56-db14-42f3-accd-76e1ff2aac04","metadata":{},"source":["<h1>Test Uniform, Default and Xavier Uniform Initialization on MNIST dataset with tanh activation</h1>\n"]},{"cell_type":"markdown","id":"6ab695dd-bfa6-43b7-8865-689d3c53af9d","metadata":{},"source":["\n","<h3>Objective for this Notebook<h3>    \n","<h5> 1. Define Several Neural Network, Criterion function, Optimizer</h5>\n","<h5> 2. Test Uniform, Default and Xavier Initialization </h5>     \n","\n"]},{"cell_type":"markdown","id":"e242f39e-2fa3-4b26-9cc9-82c1a0c80fbc","metadata":{},"source":["<h2>Table of Contents</h2>\n","In this lab, you will test PyTroch Default Initialization, Xavier Initialization and Uniform Initialization on the MNIST dataset. \n","\n","<ul>\n","    <li><a href=\"#Model\">Neural Network Module and Training Function</a></li>\n","    <li><a href=\"#Make\">Make Some Data</a></li>\n","    <li><a href=\"#Cost\">Define Several Neural Network, Criterion function, Optimizer</a></li>\n","    <li><a href=\"#Train\">Test Uniform, Default and Xavier Initialization</a></li>\n","    <li><a href=\"#Result\">Analyze Results</a></li>\n","</ul>\n","\n","<hr>\n"]},{"cell_type":"markdown","id":"e3218828-1a43-414d-9af6-38b89b92aa79","metadata":{},"source":["<h2>Preparation</h2>\n"]},{"cell_type":"markdown","id":"aa908013-f126-41c7-9cda-6e029211c4d0","metadata":{},"source":["We'll need the following libraries:  \n"]},{"cell_type":"code","execution_count":null,"id":"527cd298-079c-441f-921d-5da8b83070e3","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Import the libraries we need to use in this lab\n","\n","# Using the following line code to install the torchvision library\n","# !mamba install -y torchvision\n","\n","import torch \n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","import matplotlib.pylab as plt\n","import numpy as np\n","\n","torch.manual_seed(0)"]},{"cell_type":"markdown","id":"701a7bc9-434a-4cfe-8dae-980e414b35d3","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"6f684e8c-0584-417c-a772-16bbfd899958","metadata":{},"source":["<h2 id=\"Model\">Neural Network Module and Training Function</h2> \n"]},{"cell_type":"markdown","id":"72eb6d27-97f9-4ff5-b0ad-7798eb42cac7","metadata":{},"source":["Define the neural network module or class with Xavier Initialization\n"]},{"cell_type":"code","execution_count":null,"id":"53b93f03-d102-446c-b541-7125291e6848","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Define the neural network with Xavier initialization\n","\n","class Net_Xavier(nn.Module):\n","    \n","    # Constructor\n","    def __init__(self, Layers):\n","        super(Net_Xavier, self).__init__()\n","        self.hidden = nn.ModuleList()\n","\n","        for input_size, output_size in zip(Layers, Layers[1:]):\n","            linear = nn.Linear(input_size, output_size)\n","            torch.nn.init.xavier_uniform_(linear.weight)\n","            self.hidden.append(linear)\n","    \n","    # Prediction\n","    def forward(self, x):\n","        L = len(self.hidden)\n","        for (l, linear_transform) in zip(range(L), self.hidden):\n","            if l < L - 1:\n","                x = torch.tanh(linear_transform(x))\n","            else:\n","                x = linear_transform(x)\n","        return x"]},{"cell_type":"markdown","id":"04c00be5-54a6-4fdf-84d3-71f723f4e2e5","metadata":{},"source":["Define the neural network module with Uniform Initialization:\n"]},{"cell_type":"code","execution_count":null,"id":"fa4fdff1-ae98-42fa-8523-84e301ff4c30","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Define the neural network with Uniform initialization\n","\n","class Net_Uniform(nn.Module):\n","    \n","    # Constructor\n","    def __init__(self, Layers):\n","        super(Net_Uniform, self).__init__()\n","        self.hidden = nn.ModuleList()\n","\n","        for input_size, output_size in zip(Layers, Layers[1:]):\n","            linear = nn.Linear(input_size, output_size)\n","            linear.weight.data.uniform_(0, 1)\n","            self.hidden.append(linear)\n","    \n","    # Prediction\n","    def forward(self, x):\n","        L = len(self.hidden)\n","        for (l, linear_transform) in zip(range(L), self.hidden):\n","            if l < L - 1:\n","                x = torch.tanh(linear_transform(x))\n","            else:\n","                x = linear_transform(x)\n","        return x"]},{"cell_type":"markdown","id":"740ab3d1-dd41-4894-9a2e-ff59f86668c3","metadata":{},"source":["Define the neural network module with PyTroch Default Initialization\n"]},{"cell_type":"code","execution_count":null,"id":"252e1fa4-baf5-4bc4-a1ec-5ca0d2eb348e","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Define the neural network with Default initialization\n","\n","class Net(nn.Module):\n","    \n","    # Constructor\n","    def __init__(self, Layers):\n","        super(Net, self).__init__()\n","        self.hidden = nn.ModuleList()\n","\n","        for input_size, output_size in zip(Layers, Layers[1:]):\n","            linear = nn.Linear(input_size, output_size)\n","            self.hidden.append(linear)\n","    \n","    # Prediction\n","    def forward(self, x):\n","        L = len(self.hidden)\n","        for (l, linear_transform) in zip(range(L), self.hidden):\n","            if l < L - 1:\n","                x = torch.tanh(linear_transform(x))\n","            else:\n","                x = linear_transform(x)\n","        return x"]},{"cell_type":"markdown","id":"ffd7e02e-dd37-4a84-be84-024e4866b734","metadata":{},"source":["Define a function to train the model, in this case the function returns a Python dictionary to store the training loss and accuracy on the validation data \n"]},{"cell_type":"code","execution_count":null,"id":"1a6693be-3c7a-4ba0-ab45-6a1186ce023e","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# function to Train the model\n","\n","def train(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n","    i = 0\n","    loss_accuracy = {'training_loss':[], 'validation_accuracy':[]}  \n","    \n","    for epoch in range(epochs):\n","        for i,(x, y) in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            z = model(x.view(-1, 28 * 28))\n","            loss = criterion(z, y)\n","            loss.backward()\n","            optimizer.step()\n","            loss_accuracy['training_loss'].append(loss.data.item())\n","            \n","        correct = 0\n","        for x, y in validation_loader:\n","            yhat = model(x.view(-1, 28 * 28))\n","            _, label = torch.max(yhat, 1)\n","            correct += (label==y).sum().item()\n","        accuracy = 100 * (correct / len(validation_dataset))\n","        loss_accuracy['validation_accuracy'].append(accuracy)\n","        \n","    return loss_accuracy"]},{"cell_type":"markdown","id":"371fa1ca-f13b-4b26-b48f-34ecb6261a07","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"6334d4ce-7601-4df2-b249-38ecb39fd808","metadata":{},"source":["<h2 id=\"Makeup_Data\">Make Some Data</h2> \n"]},{"cell_type":"markdown","id":"42a3caab-3f74-47d3-89a9-4751a072969a","metadata":{},"source":["Load the training dataset by setting the parameters <code>train </code> to <code>True</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n"]},{"cell_type":"code","execution_count":null,"id":"9cc3046d-e72d-4fca-ba45-76ed90d225a4","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Create the train dataset\n","\n","train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"2e6b9a72-fd61-4d57-ae34-f18784fd04f9","metadata":{},"source":["Load the testing dataset by setting the parameters <code>train</code> to <code>False</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n"]},{"cell_type":"code","execution_count":null,"id":"3b7e8144-503e-4c0d-8d31-706f91355a94","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Create the validation dataset\n","\n","validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"1b5f491d-068a-4f11-b9d8-5ea0a3ddc85f","metadata":{},"source":["Create the training-data loader and the validation-data loader object \n"]},{"cell_type":"code","execution_count":null,"id":"65184679-e9fc-4b86-8a1d-c6a068963b4d","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Create Dataloader for both train dataset and validation dataset\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n","validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"]},{"cell_type":"markdown","id":"032f6cbd-3efb-487f-8032-b7e3d40299ff","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"8ec67de0-6c4c-4720-813b-25d43f2ec56c","metadata":{},"source":["<h2 id=\"Cost\">Define Neural Network, Criterion function, Optimizer and Train the Model</h2> \n"]},{"cell_type":"markdown","id":"0f958b58-5acd-4cd5-b1f0-2a7257e78d7a","metadata":{},"source":["Create the criterion function\n"]},{"cell_type":"code","execution_count":null,"id":"fd20f346-44c5-4b01-98de-554f6a477d01","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Define criterion function\n","\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","id":"4fad7e21-653d-48c6-a7f5-d8754babfe65","metadata":{},"source":["Create the model with 100 hidden layers  \n"]},{"cell_type":"code","execution_count":null,"id":"60a41abe-ce79-4e6b-864b-5e3b9d3980dd","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Set the parameters\n","\n","input_dim = 28 * 28\n","output_dim = 10\n","layers = [input_dim, 100, 10, 100, 10, 100, output_dim]\n","epochs = 15"]},{"cell_type":"markdown","id":"21a24726-94c8-4fcd-83ca-4f928baf8343","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"e1b5e299-80df-4612-8c68-ed8261419756","metadata":{},"source":["<h2 id=\"Train\">Test PyTorch Default Initialization, Xavier Initialization, Uniform Initialization</h2> \n"]},{"cell_type":"markdown","id":"b2b9b9b4-54de-433e-95cf-4e4e8586a8d6","metadata":{},"source":["Train the network using PyTorch Default Initialization\n"]},{"cell_type":"code","execution_count":null,"id":"6d941fab-4fca-4c80-8860-e1fc5401efcd","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Train the model with default initialization\n","\n","model = Net(layers)\n","learning_rate = 0.01\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]},{"cell_type":"markdown","id":"59263979-ec3f-496c-a112-b06d33eeff6c","metadata":{},"source":["Train the network using Xavier Initialization function\n"]},{"cell_type":"code","execution_count":null,"id":"4033cb41-5fe9-47bb-b2ef-04d7d1177cc6","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Train the model with Xavier initialization\n","\n","model_Xavier = Net_Xavier(layers)\n","optimizer = torch.optim.SGD(model_Xavier.parameters(), lr=learning_rate)\n","training_results_Xavier = train(model_Xavier, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]},{"cell_type":"markdown","id":"0867dc68-11f7-4b45-808d-808d5b173771","metadata":{},"source":["Train the network using Uniform Initialization\n"]},{"cell_type":"code","execution_count":null,"id":"9e91cd5d-efe4-4dc4-b8b9-449705678f38","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Train the model with Uniform initialization\n","\n","model_Uniform = Net_Uniform(layers)\n","optimizer = torch.optim.SGD(model_Uniform.parameters(), lr=learning_rate)\n","training_results_Uniform = train(model_Uniform, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]},{"cell_type":"markdown","id":"c14eb8b1-e638-44ca-95e3-64aa12b67683","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"5398f093-155c-4568-bf50-a45a0b5a4b12","metadata":{},"source":["<h2 id=\"Result\">Analyse Results</h2> \n"]},{"cell_type":"markdown","id":"432a6e59-5c38-45bd-aed5-6cb1f75e4073","metadata":{},"source":["Compare the training loss for each initialization\n"]},{"cell_type":"code","execution_count":null,"id":"75e9c2c9-0084-42fd-acae-cada477c3a38","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Plot the loss\n","\n","plt.plot(training_results_Xavier['training_loss'], label='Xavier')\n","plt.plot(training_results['training_loss'], label='Default')\n","plt.plot(training_results_Uniform['training_loss'], label='Uniform')\n","plt.ylabel('loss')\n","plt.xlabel('iteration ')  \n","plt.title('training loss iterations')\n","plt.legend()"]},{"cell_type":"markdown","id":"b3795d51-22ae-4fa5-9c08-77e78f53aa93","metadata":{},"source":["compare the validation loss for each model  \n"]},{"cell_type":"code","execution_count":null,"id":"810f1284-524a-4714-bba1-7d10cd216c8a","metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Plot the accuracy\n","\n","plt.plot(training_results_Xavier['validation_accuracy'], label='Xavier')\n","plt.plot(training_results['validation_accuracy'], label='Default')\n","plt.plot(training_results_Uniform['validation_accuracy'], label='Uniform') \n","plt.ylabel('validation accuracy')\n","plt.xlabel('epochs')   \n","plt.legend()"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}
